# -*- coding: utf-8 -*-
"""BitirmeProjesi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dewL7OdfvW_lteiXKY8Ccw46nKeNX38V

# Makine Öğrenmesi Algoritmaları İle Göğüs Kanseri Sınfılandırma
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

!ls

! ls "/gdrive/My Drive/BitirmeProjesi/"

import os 
os.chdir('/gdrive/My Drive/BitirmeProjesi')

"""Yukarı kısım Google Colab üzerinde Python kodlarını çalıştırmak için gerekli komutlardır.

Proje içerisinde Kullanılacak Kütüphaneler Eklendi
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor
from sklearn.decomposition import PCA
import warnings

"""Veri okundu, Keşifsel Veri Analizi(EDA) yapılmaya başlandı.
2 tane ana değişken bulunmaktadır.Bunlar, kötü huylu(malignant) ve iyi huylu(benign) tümör şeklindedir.
"""

warnings.filterwarnings("ignore")

data = pd.read_csv("cancer.csv")
data.drop(['Unnamed: 32','id'], inplace = True, axis = 1)

data = data.rename(columns = {"diagnosis":"target"})

sns.countplot(data["target"])
print(data.target.value_counts())

"""Verinin uzunluğuna, değişken sayısına ve ilk 5 indexde bulunan değerlere bakıldı."""

data["target"] = [1 if i.strip() == "M" else 0 for i in data.target]

print(len(data))

print(data.head())

print("Data shape ", data.shape)

data.info()

describe = data.describe()

"""Keşifsel Veri analizi.Aşağıda ilk 5 ındex değerleri gözükmektedir."""

data.head(5)

"""Korelasyon matrisi incelenmiştir.Bir değişkenin diğer her değişken ile arasındaki bağlantıya bakılmıştır."""

corr_matrix = data.corr()
sns.clustermap(corr_matrix, annot = True, fmt = ".2f")
plt.title("Correlation Between Features")
plt.show()

"""Bir üstteki grafik ile veriden pek bir sonuç çıkarımı yapılamaz bu sebeple eşik değerinde oynama yaparak, bir biri arasında ilişki oranı daha yüksek olan değişkenlere bakılmıştır."""

threshold = 0.5
filtre = np.abs(corr_matrix["target"]) > threshold
corr_features = corr_matrix.columns[filtre].tolist()
sns.clustermap(data[corr_features].corr(), annot = True, fmt = ".2f")
plt.title("Correlation Between Features w Corr Threshold 0.75")

data_melted = pd.melt(data, id_vars = "target",
                      var_name = "features",
                      value_name = "value")

plt.figure()
sns.boxplot(x = "features", y = "value", hue = "target", data = data_melted)
plt.xticks(rotation = 90)
plt.show()

"""Değişkenler arası ilişki grafiksel olarak gösterilmiştir."""

sns.pairplot(data[corr_features], diag_kind = "kde", markers = "+",hue = "target")
plt.show()

"""Veri içerisinde bulunan anormalliklerin tespiti (outlier) yapılmıştır

"""

y = data.target
x = data.drop(["target"],axis = 1)
columns = x.columns.tolist()
clf = LocalOutlierFactor()
y_pred = clf.fit_predict(x)
X_score = clf.negative_outlier_factor_

outlier_score = pd.DataFrame()
outlier_score["score"] = X_score

"""Yapılan işlemlere göre 5 tane anormol değişken şekilde karşımıza çıkmıştır."""

threshold = -2
filtre = outlier_score["score"] < threshold
outlier_index = outlier_score[filtre].index.tolist()


plt.figure()
plt.scatter(x.iloc[outlier_index,0], x.iloc[outlier_index,1],color = "blue", s = 50, label = "Outliers")
plt.scatter(x.iloc[:,0], x.iloc[:,1], color = "k", s = 3, label = "Data Points")
plt.legend()
plt.show()

radius = (X_score.max() - X_score)/(X_score.max() - X_score.min())
outlier_score["radius"] = radius
plt.scatter(x.iloc[:,0], x.iloc[:,1], s = 1000*radius, edgecolors = "r",facecolors = "none", label = "Outlier Scores")
plt.legend()
plt.show()

"""Veri setini train ve test etmek üzere hazırlıyoruz.Train işlemi ile makine öğrenmesi gerçekleştirilip test işlemi ile de makinenin öğrenim oranı ne kadar testpiti yapılacaktır."""

x = x.drop(outlier_index)
y = y.drop(outlier_index).values

test_size = 0.3
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = test_size, random_state = 42)

"""Buraya kadar verileri ilk başta inceledik daha sonra anormal değişkenlerin tespiti ve düzeltme işlemi yaptık artık veri setinde bulunan değerler hepsi bir birine yakın dereceye getirilmiş durumdadır.Aşağıda da train işleminde kullanılacak veriler gözükmektedir."""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train_df = pd.DataFrame(X_train, columns = columns)
X_train_df_describe = X_train_df.describe()
X_train_df["target"] = Y_train
X_train

data_melted = pd.melt(X_train_df, id_vars = "target",
                      var_name = "features",
                      value_name = "value")

plt.figure()
sns.boxplot(x = "features", y = "value", hue = "target", data = data_melted)
plt.xticks(rotation = 90)
plt.show()

"""Veri analizi ve düzeltmeler yapıldıktan sonra KNN algoritması kullanarak makine öğrenmesi işlemi gerçekleştirip göğüs kanseri sınıflandırma işlemini yapabiliriz"""

knn = KNeighborsClassifier(n_neighbors = 2)
knn.fit(X_train, Y_train)
y_pred = knn.predict(X_test)
cm = confusion_matrix(Y_test, y_pred)
acc = accuracy_score(Y_test, y_pred)
score = knn.score(X_test, Y_test)
print("Score: ",score)
print("CM: ",cm)
print("Basic KNN Acc: ",acc)

"""Yukarı
daki çıkan değerleri incelersek, %95 oranında bir başarı söz konusudur KNN algoritması için ayrıca 109 tane iyi huylu tümörden sadece 1 tanesini
yanlış bilmiş, 62 tane kötü huylu tümördende 7 tanesini yanlış bilmiştir.

Aşağıda ki kod satırında ise Destek Vektör Makinesi(SVC) yöntemi kullanılarak %96 oranında başarı oranı tespit edilmiştir.
"""

from sklearn.svm import SVC
svm = SVC()
svm.fit(X_train,Y_train)
y_pred = knn.predict(X_test)

score = svm.score(X_test, Y_test)
print("Score: ",score)

"""KNN algoritmasında en önemli etkenlerden biriside kullanılan paramtrelerdir.Aşağıdaki kod satırında en iyi knn paramtrelerini
bulmak için bir fonkisyon yazılarak train ve test işlmeleri üzerinden bu veri seti için en iyi parametreler belirlenmiş olup bir sonraki analiz yöntemlerinde de bu parametreler yazılan fonksiyon ile kullanılacaktır.

"""

def KNN_Best_Params(x_train, x_test, y_train, y_test):
    
    k_range = list(range(1,31))
    weight_options = ["uniform","distance"]
    print()
    param_grid = dict(n_neighbors = k_range, weights = weight_options)
    
    knn = KNeighborsClassifier()
    grid = GridSearchCV(knn, param_grid, cv = 10, scoring = "accuracy")
    grid.fit(x_train, y_train)
    
    print("Best training score: {} with parameters: {}".format(grid.best_score_, grid.best_params_))
    print()
    
    knn = KNeighborsClassifier(**grid.best_params_)
    knn.fit(x_train, y_train)
    
    y_pred_test = knn.predict(x_test)
    y_pred_train = knn.predict(x_train)
    
    cm_test = confusion_matrix(y_test, y_pred_test)
    cm_train = confusion_matrix(y_train, y_pred_train)
    
    acc_test = accuracy_score(y_test, y_pred_test)
    acc_train = accuracy_score(y_train, y_pred_train)
    print("Test Score: {}, Train Score: {}".format(acc_test, acc_train))
    print()
    print("CM Test: ",cm_test)
    print("CM Train: ",cm_train)
    
    return grid
    
    
grid = KNN_Best_Params(X_train, X_test, Y_train, Y_test)

"""Parametreler belirlendikten sonra Temel Bileşen Analizi(PCA) yapılmıştır.Burada %94 orannında bir başarı söz konusudur fakat makine öğrenme işlemlerinde başarı oranın çok yüksek olması da iyi değildir bu seferde makinenin ezberledği düşünülebilir bu yüzden bir de NCA analizi yaılacaktır.

PCA Analizi
"""

# Commented out IPython magic to ensure Python compatibility.
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

pca = PCA(n_components = 2)
pca.fit(x_scaled)
X_reduced_pca = pca.transform(x_scaled)
pca_data = pd.DataFrame(X_reduced_pca, columns = ["p1","p2"])
pca_data["target"] = y
sns.scatterplot(x = "p1", y = "p2", hue = "target", data = pca_data)
plt.title("PCA: p1 vs p2")


X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X_reduced_pca, y, test_size = test_size, random_state = 42)

grid_pca = KNN_Best_Params(X_train_pca, X_test_pca, Y_train_pca, Y_test_pca)


cmap_light = ListedColormap(['orange',  'cornflowerblue'])
cmap_bold = ListedColormap(['darkorange', 'darkblue'])

h = .05 
X = X_reduced_pca
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

Z = grid_pca.predict(np.c_[xx.ravel(), yy.ravel()])


Z = Z.reshape(xx.shape)
plt.figure()
plt.pcolormesh(xx, yy, Z, cmap=cmap_light)


plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,
            edgecolor='k', s=20)
plt.xlim(xx.min(), xx.max())
plt.ylim(yy.min(), yy.max())
plt.title("%i-Class classification (k = %i, weights = '%s')"
#           % (len(np.unique(y)),grid_pca.best_estimator_.n_neighbors, grid_pca.best_estimator_.weights))

"""Komşu Bileşenleri Analizi(NCA) analizinde %98 lik bir başarı oranı tespit edilmiştir ve  göğüs kanseri veri setinde bulunan verilerden iy-kötü huylu tümör testpiti yapılmıştır.Görsellerde verilerin ayrıştırma durumu gösterilmiştir.

NCA Analizi
"""

# Commented out IPython magic to ensure Python compatibility.
nca = NeighborhoodComponentsAnalysis(n_components = 2, random_state = 42)
nca.fit(x_scaled, y)
X_reduced_nca = nca.transform(x_scaled)
nca_data = pd.DataFrame(X_reduced_nca, columns = ["p1","p2"])
nca_data["target"] = y
sns.scatterplot(x = "p1",  y = "p2", hue = "target", data = nca_data)
plt.title("NCA: p1 vs p2")

X_train_nca, X_test_nca, Y_train_nca, Y_test_nca = train_test_split(X_reduced_nca, y, test_size = test_size, random_state = 42)

grid_nca = KNN_Best_Params(X_train_nca, X_test_nca, Y_train_nca, Y_test_nca)


cmap_light = ListedColormap(['orange',  'cornflowerblue'])
cmap_bold = ListedColormap(['darkorange', 'darkblue'])

h = .2 
X = X_reduced_nca
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

Z = grid_nca.predict(np.c_[xx.ravel(), yy.ravel()])


Z = Z.reshape(xx.shape)
plt.figure()
plt.pcolormesh(xx, yy, Z, cmap=cmap_light)


plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,
            edgecolor='k', s=20)
plt.xlim(xx.min(), xx.max())
plt.ylim(yy.min(), yy.max())
plt.title("%i-Class classification (k = %i, weights = '%s')"
#           % (len(np.unique(y)),grid_nca.best_estimator_.n_neighbors, grid_nca.best_estimator_.weights))

"""## Yapılan işlemler
# Veri analizi yapıldı
Veride bulunan değişkenler incelenerek hangi değişkenler üzerinden makine öğrenmesi yapılmasının daha uygun olabilecğeine bakıldı.
# Knn algoritması kullanıldı.
%95'lik bir doğruluk oranı elde edildi.
# Temelde Knn algoritması kullanılarak PCA Analizi Yapıldı.
Pca analizinde %94'lük bir doğruluk oranı elde edildi, ayrıştırma şekli grafik üzerinden gösterildi.
# Yine temelde Knn algoritması kullanılarak NCA Analizi Yapıldı.
Tekrardan farklı bir analiz yapılmasının sebebi, makinenin öğrenmekten ziyade ezberledği göz önüne alındığı için yapılmıştır.Sonuç göstermiştir ki makine öğrenmeye devam etmiş ve en yüksek doğruluk oranı %98 ile ortaya çıkmış ve verilerin ayrıştırması şekilde gösterilmiştir.
"""

